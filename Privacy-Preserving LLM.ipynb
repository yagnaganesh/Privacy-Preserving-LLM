{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCh94WbwmAzqyNyANdRlYh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yagnaganesh/ML/blob/main/Working_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CK8vlmJSjfWy"
      },
      "outputs": [],
      "source": [
        "pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "class edmodel:\n",
        "  def __init__(self):\n",
        "\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=api_key)\n",
        "    user_prompt = input(\"Enter the prompt\")\n",
        "    prompt,info = self.pre_process(user_prompt)\n",
        "    text_generated=self.process(prompt)\n",
        "    final_response=self.post_process(text_generated,info)\n",
        "    print(final_response)\n",
        "\n",
        "  def pre_process(self,user_prompt):\n",
        "    model = genai.GenerativeModel(\n",
        "        \"gemini-2.5-flash\",\n",
        "        system_instruction=\"you're assistant that removes personal information from the prompt and replaces it with random information. once it is done give responce such that 1st line contains new prompt and 2nd line conatains personal information and context where is being used\"\n",
        "    )\n",
        "    response = model.generate_content(user_prompt)\n",
        "    s=response.text.split(\"\\n\")\n",
        "    print(s[0],s[1])\n",
        "    return s[0],s[1]\n",
        "\n",
        "\n",
        "  def process(self,user_prompt):\n",
        "\n",
        "    model=genai.GenerativeModel(\n",
        "        \"gemini-2.5-flash\")\n",
        "    response = model.generate_content(user_prompt)\n",
        "    return response.text\n",
        "\n",
        "  def post_process(self,text_generated,info):\n",
        "    model = genai.GenerativeModel(\n",
        "        \"gemini-2.5-flash\",\n",
        "        system_instruction=f\"you're assistant that replaces personal information from the response and adds information using {info}\"\n",
        "    )\n",
        "\n",
        "    response = model.generate_content(text_generated)\n",
        "    return response.text\n",
        "\n",
        "\n",
        "c=edmodel()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "Mk1VZXlVj1Gj",
        "outputId": "55c02998-4c0f-4c47-f5d0-05b42efa9129"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the promptyagna is in bengalore in 21.00pm at whitefield want to go to iskon continue the story in 200 words\n",
            "Alex is in New York City at 10:30 AM near Times Square and wants to go to the Empire State Building. Continue the story in 200 words. yagna (name), bengalore (city), 21.00pm (time), whitefield (location), iskon (destination) are the personal information used in the context of a story prompt.\n",
            "\"Metro it is,\" Yagna murmured, eager to swap the chaotic energy of Bangalore's bustling streets for another iconic city experience. He navigated the throngs of people and the evening traffic, his map app guiding him towards the sprawling Whitefield Metro station. It was already **21.00pm**, and the air grew thick with the rumble of unseen trains and the cacophony of hurried announcements echoing through the vast space.\n",
            "\n",
            "Descending into the labyrinthine station, Yagna quickly located the platform for the Purple Line. A train rumbled in within minutes, a surge of people exiting as he joined the inbound flow. The ride was brief, just a few stops. As he emerged from the Metro, the majestic dome of ISKCON immediately dominated the skyline, surprisingly close. Yagna grinned, a fresh wave of excitement washing over him, ready to finally see the temple in all its glory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wX7D4wvsHfYz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}